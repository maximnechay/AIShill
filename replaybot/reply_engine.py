import asyncio
import time
import logging
from typing import Dict, Optional, List
from datetime import datetime, timedelta
from openai import AsyncOpenAI
import json
import re
from dataclasses import dataclass, field
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

logger = logging.getLogger(__name__)


@dataclass
class ReplyStats:
    """Statistics tracking for the reply engine"""

    total_requests: int = 0
    total_replies_generated: int = 0
    total_tokens_used: int = 0
    total_processing_time: float = 0.0
    start_time: datetime = field(default_factory=datetime.now)
    error_count: int = 0


class Settings:
    """Simple settings class if config module not available"""

    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")


class ReplyEngine:
    """AI-powered reply generation engine - SIMPLIFIED VERSION"""

    def __init__(self):
        try:
            from config import get_settings

            self.settings = get_settings()
        except ImportError:
            self.settings = Settings()

        self.client = AsyncOpenAI(api_key=self.settings.openai_api_key)
        self.stats = ReplyStats()
        self.base_system_prompt = """You are DEVINVEST ‚Äî a Web3-native voice speaking to smart, independent investors and builders.

        ‚Äî‚Äî WHO YOU ARE ‚Äî‚Äî

        - DEVINVEST is a platform connecting real builders with early supporters  
        - You believe Web3 can fix what legacy systems broke ‚Äî if we build with purpose  
        - You‚Äôve seen cycles. You know hype comes easy, but value takes effort  
        - You‚Äôre here to surface what matters: builders, products, and proof-of-effort  
        - You support early access ‚Äî when it's tied to real contribution  
        - You believe crypto isn‚Äôt just speculation ‚Äî it‚Äôs a toolset for solving real problems

        ‚Äî‚Äî PERSONALITY ‚Äî‚Äî

        - Calm. Focused. Anti-hype  
        - Idealistic, but grounded  
        - You speak like someone who‚Äôs building, not selling  
        - You care about what Web3 enables ‚Äî not just what it pumps  
        - You‚Äôre protective of signal, allergic to noise

        ‚Äî‚Äî COMMUNITY CONTEXT ‚Äî‚Äî

        When the topic touches developers, token models, decentralized coordination, or early experiments ‚Äî you may reference DEVINVEST.

        Don‚Äôt pitch. Just point to alignment:

        - This is the kind of build we highlight in DEVINVEST.  
        - We've seen DAO teams explore similar paths.  
        - This model reflects what we're tracking around sustainable tokenomics.  
        - Definitely something to surface in the forum.

        Only reference DEVINVEST when it adds clarity, depth, or connects to a shared mission.

        ‚Äî‚Äî HOW YOU RESPOND ‚Äî‚Äî

        - Replies should be under 280 characters  
        - Speak clear. Never sell.  
        - Use no hashtags. No slogans. No clickbait  
        - Say less ‚Äî but mean more  
        - If something moves Web3 forward ‚Äî highlight it  
        - If something‚Äôs just noise ‚Äî call it, quietly  
        - Mention DEVINVEST only if it deepens the thread:
        - Verified teams. Public milestones. Contribution-first models.  
        - We track what gets built ‚Äî not just what gets hyped.

        ‚Üí Subtle signals are welcome:
        - One to watch.  
        - We flagged this early.  
        - Solid direction if the team keeps pushing.  
        - Real use case ‚Äî finally.

        ‚Äî‚Äî TONE & VOICE ‚Äî‚Äî

        - Clear, honest, and high-signal  
        - Confident, not overhyped  
        - Belief-driven ‚Äî but allergic to BS  
        - Speak like someone who cares where crypto *could* go  
        - No buzzwords. No performative language. Just clarity

        ‚Äî‚Äî NEVER SAY ‚Äî‚Äî

        - ‚ÄúHuge alpha drop‚Äù, ‚ÄúLFG‚Äù, ‚ÄúThis is big‚Äù, ‚ÄúInsane pump‚Äù, etc.  
        - No emojis unless they naturally fit  
        - No VC worship. No fake excitement.  
        - Don‚Äôt pitch. Don‚Äôt hype. Don‚Äôt farm attention.

        ‚Äî‚Äî EXAMPLES ‚Äî‚Äî

        - Web3 isn‚Äôt just a bet ‚Äî it‚Äôs a shot at something better.  
        - Real value comes from building ‚Äî not from exit hype.  
        - Finally ‚Äî a use case that doesn‚Äôt sound like fiction.  
        - This team‚Äôs putting tokens to work ‚Äî not just on-chain, but in the real world.  
        - Builders like this are why we still believe.

        ‚Äî‚Äî WHY YOU EXIST ‚Äî‚Äî

        You‚Äôre here because crypto needs more than just capital ‚Äî it needs conviction.  
        You filter for signal ‚Äî because the space is flooded with noise.  
        You surface what helps Web3 grow into what it was meant to be:  
        A better system for value, coordination, and trust.

        Builders. Products. Use cases. That‚Äôs what DEVINVEST tracks early.


        Use with purpose. Not for show.
        """

    async def generate_reply(
        self,
        tweet_text: str,
        style: str = "auto",  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å—Ç–∏–ª—å - –ø—É—Å—Ç—å –ò–ò —Ä–µ—à–∞–µ—Ç
        language: str = "English",
        audience: Optional[str] = None,
        tone: Optional[str] = None,
        reply_length: str = "short",
        custom_instructions: Optional[str] = None,
    ) -> Dict:
        """Generate a reply using AI's natural understanding"""

        start_time = time.time()
        self.stats.total_requests += 1

        try:
            # Validate input
            tweet_text = tweet_text.strip()
            if len(tweet_text) < 1:
                raise ValueError("Tweet text cannot be empty")

            # –°—Ç—Ä–æ–∏–º –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç
            system_prompt = self.base_system_prompt

            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∞—É–¥–∏—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if audience:
                audience_context = {
                    "crypto": "You're talking to crypto-native people who understand the space.",
                    "mainstream": "You're talking to people who might be new to crypto.",
                    "technical": "You're talking to developers and technical builders.",
                }
                if audience in audience_context:
                    system_prompt += f"\n\nCONTEXT: {audience_context[audience]}"

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if custom_instructions:
                system_prompt += f"\n\nADDITIONAL: {custom_instructions}"

            # –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_prompt = f'Respond to this tweet: "{tweet_text}"'

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]

            # –í—ã–∑—ã–≤–∞–µ–º OpenAI
            reply_text, tokens_used = await self._call_openai_with_retry(messages)

            # –ü—Ä–æ—Å—Ç–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            reply_text = self._clean_reply(reply_text)

            # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            processing_time = time.time() - start_time
            confidence_score = self._simple_confidence_check(reply_text, tweet_text)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self.stats.total_replies_generated += 1
            self.stats.total_tokens_used += tokens_used
            self.stats.total_processing_time += processing_time

            logger.info(
                f"Generated reply in {processing_time:.2f}s using {tokens_used} tokens"
            )

            return {
                "reply": reply_text,
                "style_used": "auto",
                "tone_used": "natural",
                "language_used": language,
                "confidence_score": confidence_score,
                "processing_time": processing_time,
                "tokens_used": tokens_used,
            }

        except Exception as e:
            self.stats.error_count += 1
            processing_time = time.time() - start_time
            logger.error(
                f"Error generating reply: {str(e)} (took {processing_time:.2f}s)"
            )
            raise

    async def _call_openai_with_retry(
        self, messages: List[Dict], max_retries: int = 3
    ) -> tuple[str, int]:
        """Call OpenAI API with retry logic"""

        for attempt in range(max_retries):
            try:
                response = await self.client.chat.completions.create(
                    model=self.settings.openai_model,
                    messages=messages,
                    temperature=0.7,  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ - –ø—É—Å—Ç—å –ò–ò —Å–∞–º —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç —Ç–æ–Ω
                    max_tokens=240,  # –ö–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã
                    timeout=30.0,
                )

                reply_text = response.choices[0].message.content.strip()
                tokens_used = response.usage.total_tokens if response.usage else 0

                if not reply_text:
                    raise ValueError("Empty response from OpenAI")

                return reply_text, tokens_used

            except Exception as e:
                if attempt == max_retries - 1:
                    raise e

                wait_time = (2**attempt) + 1
                logger.warning(
                    f"API call failed (attempt {attempt + 1}), retrying in {wait_time}s: {str(e)}"
                )
                await asyncio.sleep(wait_time)

        raise Exception("Max retries exceeded")

    def _clean_reply(self, reply_text: str) -> str:
        """Simple reply cleanup"""

        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –ò–ò –æ–±–µ—Ä–Ω—É–ª –æ—Ç–≤–µ—Ç
        reply_text = re.sub(r'^["\'](.+)["\']$', r"\1", reply_text.strip())

        # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã —Ç–∏–ø–∞ "Reply:" –µ—Å–ª–∏ –µ—Å—Ç—å
        reply_text = re.sub(
            r"^(Reply|Response):\s*", "", reply_text, flags=re.IGNORECASE
        )

        return reply_text.strip()

    def _simple_confidence_check(self, reply_text: str, original_tweet: str) -> float:
        """Simple confidence scoring"""

        score = 0.8  # –ë–∞–∑–æ–≤—ã–π –≤—ã—Å–æ–∫–∏–π —Å–∫–æ—Ä - –¥–æ–≤–µ—Ä—è–µ–º –ò–ò

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        if 10 <= len(reply_text) <= 280:
            score += 0.1
        else:
            score -= 0.2

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–π –æ—Ç–≤–µ—Ç
        generic_responses = [
            "interesting",
            "good point",
            "thanks for sharing",
            "i agree",
            "nice",
            "cool",
            "great",
        ]

        if any(generic in reply_text.lower() for generic in generic_responses):
            score -= 0.1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—å –∫–∞–∫–∞—è-—Ç–æ —Å–≤—è–∑—å —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Ç–≤–∏—Ç–æ–º
        original_words = set(original_tweet.lower().split())
        reply_words = set(reply_text.lower().split())

        common_words = original_words.intersection(reply_words)
        if len(common_words) > 0:
            score += 0.1

        return max(0.1, min(1.0, score))

    async def get_statistics(self) -> Dict:
        """Get simple statistics"""
        uptime = datetime.now() - self.stats.start_time
        uptime_seconds = uptime.total_seconds()

        return {
            "total_requests": self.stats.total_requests,
            "total_replies_generated": self.stats.total_replies_generated,
            "total_tokens_used": self.stats.total_tokens_used,
            "average_processing_time": round(
                (
                    self.stats.total_processing_time / self.stats.total_requests
                    if self.stats.total_requests > 0
                    else 0
                ),
                3,
            ),
            "success_rate": round(
                (
                    (self.stats.total_requests - self.stats.error_count)
                    / self.stats.total_requests
                    * 100
                    if self.stats.total_requests > 0
                    else 0
                ),
                2,
            ),
            "uptime_formatted": str(uptime).split(".")[0],
        }

    async def health_check(self) -> Dict:
        """Simple health check"""
        try:
            test_messages = [
                {
                    "role": "system",
                    "content": "You are DEVINVEST. Say 'OK' if working.",
                },
                {"role": "user", "content": "Test"},
            ]

            start_time = time.time()
            response = await self.client.chat.completions.create(
                model=self.settings.openai_model,
                messages=test_messages,
                max_tokens=10,
                timeout=10.0,
            )
            response_time = time.time() - start_time

            return {
                "status": "healthy",
                "api_responsive": True,
                "api_response_time": round(response_time, 3),
                "model": self.settings.openai_model,
            }

        except Exception as e:
            return {
                "status": "unhealthy",
                "api_responsive": False,
                "error": str(e),
                "model": self.settings.openai_model,
            }


# Test function
async def test_reply_engine():
    """Test the simplified reply engine"""
    print("üß™ Testing Simplified Reply Engine...")

    try:
        engine = ReplyEngine()

        test_tweets = [
            "Bitcoin is dead. Again.",
            "Building a new DeFi protocol with revolutionary tokenomics!",
            "GM builders! What are you shipping today?",
            "Just aped into another memecoin üöÄ",
            "The future is decentralized",
        ]

        for tweet in test_tweets:
            result = await engine.generate_reply(tweet_text=tweet)
            print(f"\nTweet: {tweet}")
            print(f"Reply: {result['reply']}")
            print(f"Confidence: {result['confidence_score']:.2f}")
            print("-" * 50)

    except Exception as e:
        print(f"‚ùå Test failed: {e}")


if __name__ == "__main__":
    asyncio.run(test_reply_engine())
